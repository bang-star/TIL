# CS(5일차) - 1일 1로그 100일 IT 지식

## 1-14 프로세서는 무조건 빠른게 좋을까?
  
  - 프로세서는 인출, 해석, 실행 사이클을 계속 반복 수행한다.

    - 우선 메모리에서 다음에 처리할 명령어를 인출한다. 
    
        보통은 다음 메모리에 위치에 저장된 명령어지만, GOTO나 IFZERO가 명시하는 위치에 있는 명령어인 위치에 있는 명령어일 수도 있다. 이어서 가져온 명령어를 해석한다. 
        
        즉, 명령어가 무슨 일을 하는지 파악하고 명령어를 수행하는데 필요한 모든 준비를 마치는 것을 의미한다.

    - 명령어를 실행한다.

        명령어 실행은 메모리에서 정보를 가져오고, 산술 연산이나 논리 연산을 수행하며, 그 결과를 저장하는 일련의 작업을 명령어에 따라 적절하게 조합함으로써 이루어진다.
        
     - 명령어 실행 후 인출 단계로 되돌아간다.

        실제 프로세서의 인출, 해석, 실행 사이클에는 전체 과정이 빨리 돌아가게 하는 정교한 메커니즘이 사용된다.

  - 실제 컴퓨터에는 모형 컴퓨터보다 많은 명령어가 있지만, 기본 명령어의 유형은 같다.
  
    실제 컴퓨터에는 데이터를 옮기고 산술 연산을 수행하거나 다양한 크기와 종류의 수로 연산하고, 비교 또는 분기하고, 컴퓨터의 나머지 부분을 제어하는 부분이 더 많다.

    일반적으로 프로세서에는 수십 개에서 수백 개의 명령어가 있고, 명령어와 데이터는 여러 개의 메모리 위치를 차지한다(보통 2-8바이트)

    실제 프로세서에는 누산기가 여러개(보통 16 또는 32개) 있어서, 초고속 메모리 역할을 하는 누산기에 중간 결과를 하나 이상 담을 수 있다.

  - 컴퓨터 아키텍처
    
    - 컴퓨터 아키텍처는 프로세서 설계와 더불어 프로세서와 컴퓨터 나머지 부분 간의 연결 방식 설계를 다루는 분야다.
    
    - 대학에서 컴퓨터 아키텍처는 흔히 컴퓨터과학과 전기 공학 및 전자 공학의 경계에 있는 하위 분야다.
    
    - 컴퓨터 아키텍처 분야의 주요 관심사 중 하나는 명령어 집합이다.
    
        - 명령어 집합이란 프로세서가 제공하는 명령어 레퍼토리를 뜻한다. 

        - 폭넓고 다양한 종류의 계산이 처리되도록 많은 수의 명령어가 있는 것이 좋을까? 반대로 작성하기 쉽고 다양한 종류의 계산이 처리되도록 더 적은 수의 명령어가 있는 것이 좋을까?

            컴퓨터 아키텍처는 기능성, 속도, 복잡도, 전력 소모 정도, 프로그램 가능성 등 상충하는 요구 간 복잡한 트레이드오프를 수반한다.

            폰 노이만의 말을 인용하면 "일반적으로 산술 장치의 내부 자원 운영은 빠른 연산 속도에 대한 욕구와 기계의 단순성 또는 저비용에 대한 욕구 사이의 절충으로 결정된다."

    - 프로세서는 메모리를 비롯한 컴퓨터의 나머지 부분과 어떻게 연결되어 있을까?

        프로세서 속도는 매우 빨라서 명령어 한 개를 1나노초보다 훨씬 더 짧은 시간 내에 수행한다.

        그에 비해 메모리는 몹시 느리다. 데이터와 명령어를 메모리에서 인출하는 데 10~20 나노초 정도 걸린다.

        절대적으로는 빠르지만, 프로세서 관점에서는 느리다. 

        데이터가 도착하기를 기다릴 필요가 없다면 프로세서는 명령어 수십 개를 실행하고도 남을 시간이기 때문이다.

     - 현대 컴퓨터 아키텍처는 캐시라는 고속 메모린를 몇개 사용한다.

        캐시는 프로세서와 메모리 사이에 있고 최근 사용된 명령어와 데이터를 담고 있다.

        캐시에서 찾을 수 있는 정보에 접근하는 편이 메모리에서 정보가 오기를 기다리는 것보다 빠르다.

    - 컴퓨터 설계자들은 프로세서가 더 빨리 작동하도록 만들기 위해 여러 가지 앜키텍처 기법을 동원한다.

        - 파이프라이닝

            - 인출과 실행 단계가 겹치도록 프로세서를 명령어가 여러개가 다양한 단계에 걸쳐 진행되도록 만들 수 있다.

            - 자동차 조립 라인을 따라 이동하는 것과 개념적으로 비슷하다.

            - 명령어 한 개가  완료되는 데는 여전히 같은 시간이 걸리지만, 여러 개의 명령어를 동시에 처리하므로 전체적인 처리 속도는 빨라진다.
  
         - 병렬적 실행 방법
            
            - 명령어들이 서로 간섭하거나 의존하지 않는다면 다수의 명령어를 병렬적으로 실행하는 방법
            
            - 차량 생산에 비유하자면 병렬 조립 라인을 사용하는 것과 비슷하다.
            
            - 명령어들이 상호 작용하지 않는다면 가끔 명령어의 순서를 바꿔 실행하는 일도 가능하다.

        - 다중 프로세서
            
            - 프로세서 여러개가 동시에 작동하는 기법
            
            - 오늘날 노트북과 휴대폰에 사용되는 기술


            - 요즘은 단일 칩에 더 많은 프로세서 코어를 담거나, 컴퓨터마다 두 개 이상의 칩을 넣는 경향이 크다. 집적회로의 선폭이 작아질수록 칩에 트랜지스터를 더 많이 넣을 수 있는데, 보통 더 많은 코어와 캐시 메모리를 넣는데 사용된다.

                개별 프로세서는 더 이상 빨라지지 않지만, 더 많은 코어를 쓸 수 있어 실질적인 연산 속도는 꾸준히 증가하고 있다.



    - 프로세서 간에 속도를 비교하는 것은 어려울 뿐만 아니라 그다지 의미 없다.

        - 산술 연산 같은 기본적인 작업조차 일대일로 비교하기 어려울 만큼 서로 다른 방식으로 처리되기도 한다.

            예시. 어떤 프로세서는 두 수를 더하고 다른 위치에 결과를 저장하기 위해 모형 프로세서처럼 세 개의 명령어가 필요하다. 다른 프로세서는 두 개의 명령어만 필요하고 또 다른 프로세서는 그 연산을 단일 명령어로 처리한다. 하나의 프로세서가 몇 개의 명령어를 병렬적으로 처리하거나 겹쳐서 실행함으로써 명령어 처리가 단게적으로 진행되도록 할 수 있을 것이다. 프로세서가 전력 소모를 낮추고자 빠른 실행 속도를 포기하기도 하며, 심지어 전력이 배터리에서 공급되는지 아닌지에 따라 속도를 동적으로 조정하기도 한다. 일부 프로세서는 고속 코어와 저속 코어의 조합으로 구성되며, 코어 유형별로 서로 다른 작업을 할당하기도 한다.

            그러므로 어떤 프로세서가 다른 것보다 '빠르다'라는 주장은 조심스럽게 받아들여야 하며 요구사항에 따라 차이가 있을 수 있다.

<br />  
<hr />
<br />

## 1-15. 캐시가 무엇인가?

  ```
  "우리는 메모리를 계층 구조로 만들 가능성이 있음을 결국 인식하게 된다. 여기서 각 단게의 메모리는 앞 단계보다 용량은 더 크고 접근 속도는 느리다"

  - 아서 벅스, 허먼 골드스타인, 존 폰 노이만, 1946
  ```

  - 캐싱
    
    - 캐싱은 컴퓨팅 이외에도 여러 분야에 폭넓게 적용 가능한 아이디어다.

     - 프로세서에서 캐시는 용량이 작고 속도가 빠른 메로리로, 용량이 더 크지만 훨씬 느린 주 기억 장치에 매번 겁근하는 것을 피하고자 최근에 사용된 정보를 저장하는 데 사용된다.

     - 프로세서는 일반적으로 여러 그룹의 데이터와 명령어에 짧은 간격으로 잇달아 여러 번 접근한다.

     - 일반적인 프로세서에는 캐시가 2~3개 있는데, 흔히 L1, L2, L3 레벨이라 부르고 뒤로 갈수록 용량은 크지만 속도는 더 느리다. 가장 큰 개시는 데이터를 몇 MB 정도 담을 수 있다.

     - 캐싱이 효과적인 이유는 최근에 사용된 정보가 곧 다시 사용될 가능성이 크기 때문이다. 캐시에 정보를 포함하고 있다는 사실은 메모리 작업을 기다리는 데 시간을 덜 쓴다는 것을 뜻한다.

        캐싱 과정에서는 대개 정보를 블록 단위로 동시에 불러온다. 

        예를들어, 단일 방치트에 대한 요청이 들어오면 연속된 메모리위치를 포함된 블록을 불러온다. 그 이유는 인접한 정보라면 곧 사용될 가능성이 높으므로, 미리 불러와 두면 필요할 때 캐시에서 바로 꺼내 쓰기 쉽기 때문이다. 그렇게 되면 근처에 있는 정보를 참조할 때 기다리지 않고 바로 볼수 있을 것이다.

    - 캐싱은 성능을 크게 높이는 경우를 제외하면 사용자에게 거의 드러나지 않는다.

    - 캐싱은 우리가 뭔가를 사용하고 있고 그것을 곧 다시 쓸 가능성이 있거나 근처에 있는 뭔가를 사용할 가능성이 있을 때 언제든지 활용할 수 있는 훨씬 더 일반적인 개념이다.

        프로세서에 있는 여러 개의 누산기는 실행 속도를 높인다는 점에서는 사실상 일종의 캐시다.

        주 기억 장치는 디스크를 보완하는 캐시가 될수 있고, 메모리와 디스크는 네트워크에서 오는 데이터를 빠르게 꺼낼 수 있다는 점에서 둘다 캐시가 된다.

        네트워크에서는 멀리 떨어져 있는 서버에서 오는 정보 흐름의 속도를 높이려고 캐시를 사용할 때가 많고, 서버 자체에도 캐시가 있다.

<br />  
<hr />
<br />

## Keyword

  - Tradeoff 
    
    완전 고용과 물가 안정의 관계. 
    
    곧, 실업률(失業率)을 줄이면 물가가 상승하고, 물가를 안정시키면 실업률이 높아진다는 모순적 관계를 이르는 말임.

  - ARM

    - 1980년대 중반, 영국의 컴퓨터 회사 Acorn Computer는 비즈니스용 신형 고성능 컴퓨터를 만든다는 목표를 세운다. 하지만 새 컴퓨터에 쓸 만한 기성품 CPU를 찾을 수 없자 직접 RISC 기반 CPU 아키텍처를 개발하기로 하는데, 이것이 "Acorn RISC Machine", 즉 ARM의 시작이다.

    - 80년대 말 ARM 개발 부문을 떼어내 Apple과 VLSI Technology와의 합작회사를 설립하고 이름을 ARM(Advanced RISC Machine)으로 변경하게 되었고, 이후로는 주로 저전력 위주의 SoC 형태의 CPU 개발에 집중하였다.

    - 90년대부터 2000년대 중반까지만 해도 ARM이 고성능 컨트롤러 시장에서 독주하는 상황은 아니었다. 세계적으로 보면 ARM 계열 제품들은 동아시아 쪽에서 강세였지만 일본은 MIPS나 히타치가 개발한 SH 기반 제품이 상당히 많이 쓰였고 유럽 같은 곳에서는 모토로라 계열의 68k/PPC 컨트롤러가 많이 쓰였다.

    - CPU 구조를 계속 발전시키면서 ARM의 시장 영역은 모바일 단말, PDA, 고성능 컨트롤러, DSP Codec으로 점차 확대되었으며 특히 90년대 후반에서 2000년대 중반까지 유행했던 임베디드 Linux의 열풍을 타고 SoC 계열의 제품이 시장에서 자리잡게 되었다. 이때 등장한 유명 제품이 바로 인텔의 StrongARM 계열 제품과 삼성전자의 S3C24x0 계열 제품

        ![image](https://user-images.githubusercontent.com/63120360/170398200-cf6ce420-5866-4435-baac-3434c1c2c467.png)

<br />  
<hr />
<br />

