# CS(8일차) - 1일 1로그 100일 IT 지식

### 범위 : p.76 ~ 77
<br />

```
    "그러므로 우리는 메모리를 계층 구조로 만들 가능성이 있음을 결국 인식하게 된다. 여기서 각 단계의 메몰리는 앞 단계보다 용량은 더 크고 접근 속도는 느리다" - 아서 벅스, 허먼 골드스타인, 존 폰 노이만, 1946
```

### 1. 캐싱이란
  - 캐싱은 컴퓨팅 이외에도 여러 분야에 폭넓게 적용 가능한 아이디이다.
  - 프로세서에서 캐시는 용량이 작고 속도가 빠른 메로리로, 용량이 더 크지만 훨씬 느린 주 기억 장치에 매번 겁근하는 것을 피하고자 최근에 사용된 정보를 저장하는 데 사용된다.

### 2. 캐싱이 효과적인 이유
  - 최근에 사용된 벙보가 곧 다시 사용될 가능성이 크기 때문이다.
  - 캐시에 정보를 포함하고 있다는 사실은 메모리 작업을 기다리는 데 시간을 덜 쓴다는 것을 의미한다.
  - 캐싱 과정에서 대개 정보를 블록 단위로 동시에 불러온다.
  
    예를 들어, 단일 바이트에 대한 요청이 들어오면, 연속된 메모리 위치를 포함한 블록을 불러온다. 그 이유는 인접한 정보라면 곧 사용될 가능성이 높으므로, 미리 불러와 두면 필요할 때 캐시에서 바로 꺼내 쓰기 쉽기 때문이다. 그렇게 되면 기다리지 않고 바로 볼수 있을 것이다.

### 3. 캐싱의 역할
  - 캐싱은 성능을 크게 높이는 경우를 제외하면 사용자에게 거의 드러나지 않는다.
  - 하지만 캐싱은 우리가 뭔가를 사용하고 있고 그것을 곧 다시 쓸 가능성이 있거나 근처에 있는 뭔가를 사용할 가능성이 있을 때 언제든지 화룡할 수 있는 훨씬 더 일반적인 개념이다.
  - 프로세서세 있는 여러 개의 누산기는 실행속도를 높인다는 점에서 사실상 일종의 캐시다. 주 기억 장치는 디스크를 보완하는 캐시가 될 수 있고, 메모리와 디스크는 네트워크에서 오는 데이터를 빠르게 꺼낼 수 있다는 점에서 둘 다 캐시가 된다.
  - 네트워크에서는 멀리 떨어져 있는 서버에서 오는 정보 흐름의 속도를 높이려고 캐시를 사용할 때가 많고, 서버 자체에도 캐시가 있다.
  